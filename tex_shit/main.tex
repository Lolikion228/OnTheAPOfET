\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage{ntheorem}
\usepackage{multirow}
\usepackage{amsmath, amssymb}
\usepackage{indentfirst}

\theoremstyle{break}
\theorembodyfont{\normalfont}
\theoremheaderfont{\bfseries}


\newtheorem{example}{Пример}
\newtheorem{theorem}{Теорема}

\usepackage[
left=1.5cm,    % отступ слева
right=1.5cm,   % отступ справа
top=2cm,     % отступ сверху
bottom=2cm   % отступ снизу
]{geometry}


\title{Потом тут будет титульный лист}
\author{Сивков Вячеслав}
\date{2025}

\begin{document}

\maketitle

\tableofcontents

\newpage
\section{Введение}
Рассмотрим задачу проверки гипотезы о равенстве двух
распределений

\begin{equation}
	H_0: F_1 = F_2
\end{equation}

\noindent против альтернативы

\begin{equation}
	H_1: F_1 \neq F_2
\end{equation}


\noindent в случае двух независимых выборок $X = (X_1, \ldots,X_n)$ и $Y = (Y_1, \ldots, Y_m)$ с функциями распределения $F_1$ и $F_2$ соответственно.

Один из важных частных случаев этой задачи выглядит следующим образом:
пусть размеры выборок идентичны и равны $n$, пусть $h_1, h_2 \in \mathbb{R}$, $h_1, h_2 \geqslant 0$, пусть $F(x)$ некая функция распределения. Положим
\begin{align}
	&F_1(x) = F(x) \label{eq:F1}\\
	&F_2(x) = F( x(1 + \frac{h_2}{\sqrt{n}}) +  \frac{h_1}{\sqrt{n}}). \label{eq:F2}
\end{align}

Для проверки вышеуказанной гипотезы существует множество тестов. Одними из самых известных являются: тест Вилкоксона--Манна--Уитни, тест Андерсона--Дарлинга, энергетический тест, тест Колмогорова--Смирнова и тест Крамера--фон Мизеса.
В работе~\cite{melas2024} была получена формула для асимптотической мощности энергетического теста при неких ограничениях. 

В данной работе c помощью статистического моделирования была изучена скорость сходимости эмпирических мощностей энергетического теста к асимптотической с ростом размера выборки.
Также было проведено сравнение эмпирических мощностей пяти тестов для различных $F(x), h_1, h_2, n$.





\section{Методы проверки гипотез}

Далее описаны статистики для соответствующих тестов. В каждом из тестов мы отвергаем $H_0$, если значение статистики на выборках $X, Y$ \textbf{больше} чем заранее заданное критическое значение.

\subsection{Энергетический тест (ET) }
Пусть $X = (X_1, \ldots,X_n)$ и $Y = (Y_1, \ldots, Y_m)$ независимые выборки. Статистика $\Phi_{nm}$ определяется следующим образом:

\begin{equation}
\begin{aligned}
	\Phi_{nm} = \Phi_{AB} - \Phi_{A} -\Phi_{B}, \quad
	\Phi_{A} = \frac{1}{n^2} \sum_{1 \leq i \leq j \leq n} g(|X_i - X_j|),\\
	\Phi_{B} = \frac{1}{m^2} \sum_{1 \leq i \leq j \leq n} g(|Y_i - Y_j|), \quad
	\Phi_{AB} = \frac{1}{nm} \sum_{i=1}^n \sum_{j=1}^m g(|X_i - Y_j|),
\end{aligned}
\end{equation}
где $g(x)$ - непрерывная, монотонно возрастающая функция.\\


Согласно~\cite[Теорема 1]{melas2024}, в условиях теоремы, асимптотическая мощность критерия $n\Phi_{nn}(X,Y)$ с уровнем значимости $\alpha$ равна
\begin{equation}
	1 - \Phi \left(z_{1- \frac{\alpha}{2}} - \frac{b}{a} \right) + \Phi \left( -z_{1- \frac{\alpha}{2}} - \frac{b}{a} \right), 
	\label{eq:AP}
\end{equation}

\noindent где $\Phi(t)$ -- функция стандартного нормального распределения, 
 $z_{1- \frac{\alpha}{2}}$ -- его $1- \frac{\alpha}{2}$ квантиль. А константы $a$,$b$ вычисляются, как было определено в~\cite{melas2024}. Всюду далее под статистикой для ET будет пониматься $n\Phi_{nn}$.
 
\subsection{Тест Андерсона--Дарлинга для нескольких выборок (AD)}

Пусть $k \in \mathbb{N}$ -- количество выборок. Пусть $n_i$ -- размер $i$-й выборки, $ i \in \overline{1, \ldots, k} $. Пусть $N = n_1 + \ldots + n_k$. Обозначим за $M_{ij}$ количество 
элементов $i$-й выборки, которые не больше чем $Z_{(j)}$, где $(Z_{(1)}, \ldots, Z_{(N)})$ - вариационный ряд, построенный по всем имеющимся $k$ выборкам. Тогда статистика будет выглядеть следующим образом~\cite{AD_article}:

\begin{equation}
	A_{kN}^2 = \frac{1}{N} \sum_{i=1}^k \frac{1}{n_i} \sum_{j=1}^{N-1} \frac{(NM_{ij}-jn_i)^2}{j(N-j)}.
\end{equation}



\subsection{Тест Колмогорова--Смирнова (KS)}
Пусть $X = (X_1, \ldots,X_n)$ и $Y = (Y_1, \ldots, Y_m)$ независимые выборки. Пусть $N = n + m$.
Пусть $(Z_{(1)}, \ldots, Z_{(N)})$ - вариационный ряд, построенный по выборкам $X$ и $Y$. Обозначим за $\hat{F}$ и $\hat{G}$ эмпирические функции распределения построенные по выборкам $X$ и $Y$. Тогда статистика будет выглядеть так~\cite{KS_CM_article}:
\begin{equation}
	KS = \max_{1\leq i \leq N} | \hat{F}(Z_{(i)}) - \hat{G}(Z_{(i)})  |
\end{equation}



\subsection{Тест Крамера-фон Мизеса (CM)}
Пусть $X = (X_1, \ldots,X_n)$ и $Y = (Y_1, \ldots, Y_m)$ независимые выборки. Пусть $N = n + m$.
Пусть $(Z_{(1)}, \ldots, Z_{(N)})$ - вариационный ряд, построенный по выборкам $X$ и $Y$. Обозначим за $\hat{F}$ и $\hat{G}$ эмпирические функции распределения построенные по выборкам $X$ и $Y$. Тогда статистика будет выглядеть следующим образом~~\cite{KS_CM_article}:
\begin{equation}
	CM = \frac{mn}{N^2} \sum_{i=1}^{N} (\hat{F}(Z_{(i)}) - \hat{G}(Z_{(i)}))^2
\end{equation}



\subsection{Тест Вилкоксона--Манна--Уитни (WMW)}
Пусть $X = (X_1, \ldots,X_n)$ и $Y = (Y_1, \ldots, Y_m)$ независимые выборки. Статистика будет выглядеть следующим образом~\cite{WMW_article}:
\begin{equation}
	U_{nm} = \sum_{i=1}^n \sum_{j=1}^m \chi(X_i,Y_j),
\end{equation}
где
\begin{equation}
	\chi(X_i,Y_j) = 
	\begin{cases}
		1, \ X_i \geq Y_j \\
		0, \ X_i < Y_j
	\end{cases}
\end{equation}





\section{Моделирование}
О том, как проводилось вычисление эмпирических мощностей с помощью программы на С++.

Выбираем некий тест $T(X,Y)$. Фиксируем некую функцию распределения $F(x)$. Фиксируем $n \in \mathbb{N}$ -- размер выборок. Фиксируем $h_1, h_2 \in \mathbb{R}$, $h_1, h_2 \geqslant 0$ -- параметры отличия по сдвигу и масштабу соответственно. $F_1$ и $F_2$ определяем как было указано в~\eqref{eq:F1} и~\eqref{eq:F2} соответственно. Фиксируем $\alpha \in (0,1)$ -- уровень значимости. Выбираем $N \in \mathbb{N}$ и $M \in \mathbb{N}$.

Сначала приближённо вычисляем критическое значение $c_{\alpha}$ для выбранного ранее теста так, чтобы он имел уровень значимости $\alpha$ следующим образом:

\begin{enumerate}
	\item Генерируем выборки $X^{(k)}$ и $Y^{(k)}$ размера $n$, из $F_1$, где $k \in \overline{1,\ldots, M}$.
	\item Вычисляем $T(X^{(k)}, Y^{(k)})$ для всех $k \in \overline{1,\ldots, M}$
	\item Получаем выборку из распределения $T(X,Y)$ размера $M$, по ней строим эмпирическое распределение $\hat{T}(X,Y)$.
	\item В качестве $c_{\alpha}$ берём $1 - \alpha$ квантиль $\hat{T}(X,Y)$.
\end{enumerate}

Далее, для вычисления эмпирической мощности делаем следующее:
\begin{enumerate}
	\item Генерируем $X^{(i)}, Y^{(i)}$ -- выборки размера $n$ из $F_1$ и $F_2$ соответственно, для $i \in \overline{1,\ldots, N}$.
	\item Считаем количество отвержений $H_0$ как $cnt =  \#\{ (X^{(i)},Y^{(i)}) \ | \ T(X^{(i)}, Y^{(i)}) \geqslant c_{\alpha}, \ i \in \overline{1,\ldots, N} \}$.
	\item В качестве эмпирической мощности берём $ \frac{cnt}{N}$.
\end{enumerate}

\newpage
\section{Результаты}
При вычислении значений в таблицах~\ref{tbl:ap_normal_h2_diff}--\ref{tbl:cauchy_pow_vs_h1} и на
рисунках~\ref{fig:normal_pow_vs_h2}--\ref{fig:cauchy_pow_vs_n_h1_diff}  для энергетического теста\\ $g(x) = \ln(1+x^2)$. А интегралы $J_1, J_2, J_3, J^{*}_1(h_1)$ и $J^{*}_2(h_2)$ имеют тот же смысл, как и в~\cite{melas2024}.

\begin{example}
Пусть $F(x)$ - ф-я стандартного нормального распределения. Пусть $\alpha = 0.05$, $N=5000$, $M=5000$.
С помощью численного интегрирования были получены значения:
\begin{equation*}
	J_1 = 0.810113 \hspace{0.1in} J_2 = 1.154885 \hspace{0.1in}  J_3=0.763368 \hspace{0.1in}
	\frac{J^{*}_1(h_1)}{{h_1}^2} = 0.227179   \hspace{0.1in} \frac{J^{*}_2(h_2)}{{h_2}^2} = 0.147563
\end{equation*}
В таблицах~\ref{tbl:ap_normal_h1_diff} и~\ref{tbl:ap_normal_h2_diff} представлены значения асимптотической мощности, вычисленные по формуле~\eqref{eq:AP},
и эмпирические мощности, полученные для $n = 100$, $400$, $900$, $1600$, $2000$, $3000$.
Для вычисления значений в таблице~\ref{tbl:ap_normal_h1_diff} было взято значение $h_2=0$, для вычисления значений  в таблице~\ref{tbl:ap_normal_h2_diff} было взято значение $h_1=0$.
\end{example}



%normal h2
\begin{table}[!h]
	\centering
	\caption{Значения эмпирической (EP) и асимптотической (AP) мощности ($h_2=0$)}
	\hspace*{-1.0cm}\begin{tabular}
		{lrrrrrrrrrr}
		\toprule
		& h1=1.0 & h1=2.0 & h1=3.0 & h1=4.0 & h1=5.0 & h1=6.0 & h1=7.0 & h1=8.0 & h1=9.0 & h1=10.0\\
		\midrule
		EP (n=100) & 0.095 & 0.264 & 0.514 & 0.763 & 0.912 & 0.982 & 0.997 & 0.999 & 1 & 1\\
		EP (n=400) & 0.093 & 0.259 & 0.506 & 0.761 & 0.915 & 0.983 & 0.998 & 1.000 & 1 & 1\\
		EP (n=900) & 0.099 & 0.255 & 0.509 & 0.754 & 0.904 & 0.978 & 0.997 & 1.000 & 1 & 1\\
		EP (n=1600) & 0.086 & 0.245 & 0.497 & 0.751 & 0.919 & 0.983 & 0.998 & 0.999 & 1 & 1\\
		EP (n=2000) & 0.103 & 0.264 & 0.519 & 0.771 & 0.915 & 0.981 & 0.997 & 1.000 & 1 & 1\\
		EP (n=3000) & 0.111 & 0.275 & 0.529 & 0.767 & 0.917 & 0.983 & 0.997 & 1.000 & 1 & 1\\
		\addlinespace
		AP & 0.100 & 0.257 & 0.499 & 0.742 & 0.904 & 0.975 & 0.995 & 0.999 & 1 & 1\\
		\bottomrule
	\end{tabular}
	\label{tbl:ap_normal_h1_diff}
\end{table}

%normal h1
\begin{table}[!h]
	\caption{Значения эмпирической (EP) и асимптотической (AP) мощности ($h_1=0$)}
	\centering
	\hspace*{-1.0cm}\begin{tabular}
		{lrrrrrrrrrr}
		\toprule
		& h2=0.5 & h2=1.0 & h2=1.5 & h2=2.0 & h2=2.5 & h2=3.0 & h2=3.5 & h2=4.0 & h2=4.5 & h2=5.0\\
		\midrule
		EP (n=100) & 0.046 & 0.049 & 0.070 & 0.087 & 0.134 & 0.171 & 0.234 & 0.315 & 0.408 & 0.488\\
		EP (n=400) & 0.049 & 0.070 & 0.093 & 0.134 & 0.193 & 0.283 & 0.392 & 0.511 & 0.618 & 0.742\\
		EP (n=900) & 0.056 & 0.072 & 0.098 & 0.152 & 0.217 & 0.334 & 0.447 & 0.596 & 0.705 & 0.822\\
		EP (n=1600) & 0.056 & 0.075 & 0.095 & 0.141 & 0.237 & 0.323 & 0.462 & 0.601 & 0.735 & 0.844\\
		EP (n=2000) & 0.054 & 0.068 & 0.103 & 0.147 & 0.220 & 0.335 & 0.459 & 0.610 & 0.738 & 0.840\\
		EP (n=3000) & 0.045 & 0.057 & 0.082 & 0.137 & 0.213 & 0.311 & 0.446 & 0.602 & 0.726 & 0.834\\
		\addlinespace
		AP & 0.058 & 0.082 & 0.124 & 0.183 & 0.260 & 0.351 & 0.453 & 0.557 & 0.658 & 0.749\\
		\bottomrule
	\end{tabular}
	\label{tbl:ap_normal_h2_diff}
\end{table}









\newpage


\begin{example}
	Пусть $F(x)$ - ф-я стандартного распределения Коши.\\
	Пусть $\alpha = 0.05$, $N=5000$, $M=5000$.
	С помощью численного интегрирования были получены значения:
	\begin{equation*}
		J_1 = 2.197224 \hspace{0.1in} J_2 = 9.577512 \hspace{0.1in}  J_3=6.881056 \hspace{0.1in}
		\frac{J^{*}_1(h_1)}{{h_1}^2} = 0.111110   \hspace{0.1in} \frac{J^{*}_2(h_2)}{{h_2}^2} = 0.111105
	\end{equation*}
	В таблицах  \ref{tbl:ap_cauchy_h1_diff} и \ref{tbl:ap_cauchy_h2_diff} представлены значения асимптотической мощности, вычисленные по формуле~\eqref{eq:AP},
	и эмпирические мощности, полученные для выборок размера $n = 100$, $400$, $900$, $1600$, $2000$, $3000$. Для вычисления значений в таблице~\ref{tbl:ap_cauchy_h1_diff} было взято значение $h_2=0$, для вычисления значений в таблице~\ref{tbl:ap_cauchy_h2_diff} было взято значение $h_1=0$.
\end{example}


%caychy h2 new
\begin{table}[!h]
	\centering
	\caption{Значения эмпирической (EP) и асимптотической (AP) мощности ($h_2=0$)}
	\centering
	\hspace*{-1.0cm}\begin{tabular}
		[t]{lrrrrrrrrrr}
		\toprule
		& h1=1.0 & h1=2.0 & h1=3.0 & h1=4.0 & h1=5.0 & h1=6.0 & h1=7.0 & h1=8.0 & h1=9.0 & h1=10.0\\
		\midrule
		EP (n=100) & 0.067 & 0.111 & 0.204 & 0.343 & 0.516 & 0.678 & 0.814 & 0.907 & 0.962 & 0.986\\
		EP (n=400) & 0.069 & 0.128 & 0.212 & 0.352 & 0.523 & 0.683 & 0.827 & 0.919 & 0.965 & 0.990\\
		EP (n=900) & 0.065 & 0.115 & 0.207 & 0.358 & 0.514 & 0.684 & 0.817 & 0.920 & 0.967 & 0.989\\
		EP (n=1600) & 0.080 & 0.116 & 0.229 & 0.362 & 0.530 & 0.700 & 0.835 & 0.930 & 0.967 & 0.992\\
		EP (n=2000) & 0.061 & 0.105 & 0.203 & 0.338 & 0.502 & 0.677 & 0.821 & 0.907 & 0.968 & 0.990\\
		EP (n=3000) & 0.054 & 0.106 & 0.190 & 0.312 & 0.499 & 0.659 & 0.813 & 0.913 & 0.962 & 0.990\\
		\addlinespace
		AP & 0.066 & 0.116 & 0.201 & 0.319 & 0.461 & 0.608 & 0.741 & 0.846 & 0.918 & 0.961\\
		\bottomrule
	\end{tabular}
	\label{tbl:ap_cauchy_h1_diff}
\end{table}


%cauchy h1
\begin{table}[!h]
	\caption{Значения эмпирической (EP) и асимптотической (AP) мощности ($h_1=0$)}
	\centering
	\hspace*{-1.0cm}\begin{tabular}
		{lrrrrrrrrrr}
		\toprule
		& h2=1.0 & h2=2.0 & h2=3.0 & h2=4.0 & h2=5.0 & h2=6.0 & h2=7.0 & h2=8.0 & h2=9.0 & h2=10.0\\
		\midrule
		EP (n=100) & 0.060 & 0.085 & 0.132 & 0.190 & 0.269 & 0.329 & 0.420 & 0.494 & 0.574 & 0.653\\
		EP (n=400) & 0.063 & 0.109 & 0.167 & 0.257 & 0.370 & 0.509 & 0.624 & 0.717 & 0.829 & 0.887\\
		EP (n=900) & 0.067 & 0.107 & 0.190 & 0.292 & 0.421 & 0.552 & 0.683 & 0.805 & 0.881 & 0.932\\
		EP (n=1600) & 0.058 & 0.110 & 0.179 & 0.295 & 0.431 & 0.586 & 0.720 & 0.833 & 0.902 & 0.954\\
		EP (n=2000) & 0.063 & 0.112 & 0.187 & 0.310 & 0.445 & 0.586 & 0.731 & 0.834 & 0.914 & 0.958\\
		EP (n=3000) & 0.064 & 0.114 & 0.197 & 0.309 & 0.470 & 0.617 & 0.756 & 0.852 & 0.926 & 0.967\\
		\addlinespace
		AP & 0.066 & 0.115 & 0.201 & 0.319 & 0.461 & 0.608 & 0.741 & 0.846 & 0.918 & 0.961\\
		\bottomrule
	\end{tabular}
	\label{tbl:ap_cauchy_h2_diff}
\end{table}




\vspace{0.6in}

Далее, в таблицах \ref{tbl:normal_pow_vs_h1} - \ref{tbl:cauchy_pow_vs_h2} представлены эмпирические мощности 5 тестов. На рис. \ref{fig:normal_pow_vs_h2} - рис. \ref{fig:cauchy_pow_vs_h1} представлены зависимости эмпирических мощностей от различий по масштабу/сдвигу, и на рис. \ref{fig:normal_pow_vs_n_h2_diff} - рис. \ref{fig:cauchy_pow_vs_n_h1_diff} представлены зависимости эмпирических мощностей от размера выборки.\\
\newpage


% Table for NORMAL_h2
\begin{table}[!h]
	\centering
	\caption{Стандартное нормальное распределение (h2=0)}
	\begin{tabular}{l c c c c c c} 
		\toprule
		test & sample size & h1=1.0 & h1=2.0 & h1=3.0 & h1=4.0 & h1=5.0 \\ 
		\midrule
		\multirow{3}{*}{AD} 
		& n=100 & 0.1 & 0.27 & 0.53 & 0.78 & 0.91 \\ 
		& n=400 & 0.11 & 0.28 & 0.55 & 0.78 & 0.93 \\ 
		& n=900 & 0.11 & 0.27 & 0.54 & 0.79 & 0.93 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{CM} 
		& n=100 & 0.1 & 0.27 & 0.51 & 0.76 & 0.91 \\ 
		& n=400 & 0.11 & 0.26 & 0.53 & 0.76 & 0.92 \\ 
		& n=900 & 0.1 & 0.26 & 0.51 & 0.75 & 0.91 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{ET} 
		& n=100 & 0.1 & 0.26 & 0.49 & 0.76 & 0.92 \\ 
		& n=400 & 0.1 & 0.26 & 0.51 & 0.77 & 0.92 \\ 
		& n=900 & 0.12 & 0.29 & 0.52 & 0.76 & 0.92 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{KS} 
		& n=100 & 0.09 & 0.24 & 0.46 & 0.7 & 0.87 \\ 
		& n=400 & 0.1 & 0.24 & 0.45 & 0.7 & 0.88 \\ 
		& n=900 & 0.09 & 0.23 & 0.46 & 0.69 & 0.88 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{WMW} 
		& n=100 & 0.17 & 0.38 & 0.67 & 0.86 & 0.96 \\ 
		& n=400 & 0.19 & 0.42 & 0.68 & 0.88 & 0.97 \\ 
		& n=900 & 0.16 & 0.38 & 0.66 & 0.85 & 0.96 \\ 
		\bottomrule
	\end{tabular}
	\label{tbl:normal_pow_vs_h1}
\end{table}


% Table for NORMAL_h1
\begin{table}[!h]
	\centering
	\caption{Стандартное нормальное распределение (h1=0) }
	\begin{tabular}{l c c c c c c} 
		\toprule
		test & sample size & h2=1.0 & h2=3.0 & h2=5.0 & h2=7.0 & h2=9.0 \\ 
		\midrule
		\multirow{3}{*}{AD} 
		& n=100 & 0.07 & 0.23 & 0.61 & 0.9 & 0.98 \\ 
		& n=400 & 0.07 & 0.28 & 0.75 & 0.98 & 1 \\ 
		& n=900 & 0.06 & 0.28 & 0.8 & 0.99 & 1 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{CM} 
		& n=100 & 0.05 & 0.11 & 0.3 & 0.62 & 0.84 \\ 
		& n=400 & 0.05 & 0.14 & 0.42 & 0.81 & 0.97 \\ 
		& n=900 & 0.06 & 0.15 & 0.49 & 0.88 & 0.99 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{ET} 
		& n=100 & 0.06 & 0.21 & 0.52 & 0.82 & 0.95 \\ 
		& n=400 & 0.07 & 0.27 & 0.73 & 0.97 & 1 \\ 
		& n=900 & 0.06 & 0.28 & 0.79 & 0.98 & 1 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{KS} 
		& n=100 & 0.06 & 0.13 & 0.29 & 0.54 & 0.76 \\ 
		& n=400 & 0.06 & 0.15 & 0.36 & 0.71 & 0.92 \\ 
		& n=900 & 0.06 & 0.17 & 0.43 & 0.79 & 0.96 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{WMW} 
		& n=100 & 0.06 & 0.05 & 0.06 & 0.05 & 0.06 \\ 
		& n=400 & 0.06 & 0.06 & 0.05 & 0.06 & 0.06 \\ 
		& n=900 & 0.05 & 0.06 & 0.05 & 0.05 & 0.05 \\ 
		\bottomrule
	\end{tabular}
	\label{tbl:normal_pow_vs_h2}
\end{table}



\newpage


% Table for CAUCHY_h2
\begin{table}[!h]
	\centering
	\caption{Стандартное распределение Коши (h2=0)}
	\begin{tabular}{l c c c c c c} 
		\toprule
		test & sample size & h1=1.0 & h1=3.0 & h1=5.0 & h1=7.0 & h1=9.0 \\ 
		\midrule
		\multirow{3}{*}{AD} 
		& n=100 & 0.06 & 0.21 & 0.51 & 0.81 & 0.94 \\ 
		& n=400 & 0.07 & 0.21 & 0.5 & 0.8 & 0.95 \\ 
		& n=900 & 0.07 & 0.22 & 0.54 & 0.82 & 0.96 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{CM} 
		& n=100 & 0.06 & 0.24 & 0.55 & 0.82 & 0.96 \\ 
		& n=400 & 0.07 & 0.24 & 0.55 & 0.85 & 0.97 \\ 
		& n=900 & 0.07 & 0.24 & 0.57 & 0.85 & 0.97 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{ET} 
		& n=100 & 0.07 & 0.2 & 0.51 & 0.82 & 0.96 \\ 
		& n=400 & 0.07 & 0.21 & 0.5 & 0.82 & 0.97 \\ 
		& n=900 & 0.06 & 0.21 & 0.51 & 0.83 & 0.97 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{KS} 
		& n=100 & 0.07 & 0.25 & 0.57 & 0.85 & 0.97 \\ 
		& n=400 & 0.06 & 0.26 & 0.59 & 0.87 & 0.98 \\ 
		& n=900 & 0.08 & 0.25 & 0.6 & 0.87 & 0.98 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{WMW} 
		& n=100 & 0.1 & 0.3 & 0.61 & 0.84 & 0.95 \\ 
		& n=400 & 0.1 & 0.31 & 0.61 & 0.85 & 0.96 \\ 
		& n=900 & 0.11 & 0.32 & 0.62 & 0.86 & 0.97 \\ 
		\bottomrule
	\end{tabular}
	\label{tbl:cauchy_pow_vs_h1}
\end{table}




% Table for CAUCHY_h1
\begin{table}[!h]
	\centering
	\caption{Стандартное распределение Коши (h1=0)}
	\begin{tabular}{l c c c c c c} 
		\toprule
		test & sample size & h2=1.0 & h2=3.0 & h2=5.0 & h2=7.0 & h2=9.0 \\ 
		\midrule
		\multirow{3}{*}{AD} 
		& n=100 & 0.05 & 0.09 & 0.17 & 0.3 & 0.47 \\ 
		& n=400 & 0.06 & 0.1 & 0.21 & 0.42 & 0.65 \\ 
		& n=900 & 0.05 & 0.1 & 0.23 & 0.45 & 0.71 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{CM} 
		& n=100 & 0.05 & 0.07 & 0.12 & 0.21 & 0.33 \\ 
		& n=400 & 0.05 & 0.08 & 0.16 & 0.32 & 0.52 \\ 
		& n=900 & 0.04 & 0.08 & 0.16 & 0.34 & 0.6 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{ET} 
		& n=100 & 0.05 & 0.13 & 0.27 & 0.43 & 0.6 \\ 
		& n=400 & 0.06 & 0.16 & 0.36 & 0.62 & 0.82 \\ 
		& n=900 & 0.06 & 0.17 & 0.4 & 0.69 & 0.88 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{KS} 
		& n=100 & 0.06 & 0.1 & 0.18 & 0.28 & 0.39 \\ 
		& n=400 & 0.06 & 0.11 & 0.2 & 0.34 & 0.54 \\ 
		& n=900 & 0.06 & 0.1 & 0.21 & 0.4 & 0.61 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{WMW} 
		& n=100 & 0.05 & 0.05 & 0.05 & 0.05 & 0.05 \\ 
		& n=400 & 0.04 & 0.05 & 0.04 & 0.05 & 0.04 \\ 
		& n=900 & 0.05 & 0.05 & 0.06 & 0.05 & 0.06 \\ 
		\bottomrule
	\end{tabular}
	\label{tbl:cauchy_pow_vs_h2}
\end{table}




\vspace{0.1in}



\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics/NORMAL_h1_n_EP (n_500).png}
	\caption{Зависимость эмпирических мощностей от различия по масштабу, в случае стандартных нормальных распределений с одинаковым сдвигом.}
	\label{fig:normal_pow_vs_h2}
\end{figure}


\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics/NORMAL_h2_n_EP (n_500).png}
	\caption{Зависимость эмпирических мощностей от различия по сдвигу, в случае стандартных нормальных распределений с одинаковым масштабом.}
	\label{fig:normal_pow_vs_h1}
\end{figure}



\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics/CAUCHY_h1_n_EP (n_500).png}
	\caption{Зависимость эмпирических мощностей от различия по масштабу, в случае стандартных распределений Коши с одинаковым сдвигом.}
	\label{fig:cauchy_pow_vs_h2}
\end{figure}



\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics/CAUCHY_h2_n_EP (n_500).png}
	\caption{Зависимость эмпирических мощностей от различия по сдвигу, в случае стандартных распределений Коши с одинаковым масштабом.}
	\label{fig:cauchy_pow_vs_h1}
\end{figure}



\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics2/NORMAL_h1_h2_2.5.png}
	\caption{Зависимость эмпирических мощностей от размера выборки в случае стандартных нормальных распределений, отличающихся масштабом.}
	\label{fig:normal_pow_vs_n_h2_diff}
\end{figure}



\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics2/NORMAL_h2_h1_5.0.png}
	\caption{Зависимость эмпирических мощностей от размера выборки в случае стандартных нормальных распределений, отличающихся сдвигом.}
	\label{fig:normal_pow_vs_n_h1_diff}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics2/CAUCHY_h1_h2_7.0.png}
	\caption{Зависимость эмпирических мощностей от размера выборки в случае стандартных распределений Коши, отличающихся масштабом.}
	\label{fig:cauchy_pow_vs_n_h2_diff}
\end{figure}



\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics2/CAUCHY_h2_h1_6.0.png}
	\caption{Зависимость эмпирических мощностей от размера выборки в случае стандартных распределений Коши, отличающихся сдвигом.}
	\label{fig:cauchy_pow_vs_n_h1_diff}
\end{figure}


\clearpage
Далее, в таблицах~\ref{tbl:et_comp_normal_h2}--\ref{tbl:et_comp_cauchy_h1}, $\text{ET}_1$ обозначает энергетический 
тест с $g_1(x) = \ln(1+x^2)$, а $\text{ET}_2$ обозначает энергетический тест с $g_2(x) = |x|$


% Table for NORMAL_h2
\begin{table}[!h]
	\centering
	\caption{Стандартное нормальное распределение (h2=0)}
	\begin{tabular}{l c c c c c c c c c c} 
		\toprule
		test & sample size & h1=1.0 & h1=1.5 & h1=2.0 & h1=2.5 & h1=3.0 & h1=3.5 & h1=4.0 & h1=4.5 & h1=5.0 \\ 
		\midrule
		\multirow{3}{*}{$\text{ET}_1$} 
		& n=100 & 0.1 & 0.18 & 0.28 & 0.39 & 0.53 & 0.66 & 0.76 & 0.86 & 0.91 \\ 
		& n=400 & 0.1 & 0.16 & 0.27 & 0.37 & 0.5 & 0.65 & 0.76 & 0.85 & 0.92 \\ 
		& n=900 & 0.1 & 0.15 & 0.26 & 0.37 & 0.51 & 0.64 & 0.76 & 0.85 & 0.92 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{$\text{ET}_2$} 
		& n=100 & 0.12 & 0.18 & 0.27 & 0.41 & 0.53 & 0.67 & 0.79 & 0.87 & 0.93 \\ 
		& n=400 & 0.11 & 0.18 & 0.27 & 0.41 & 0.56 & 0.68 & 0.77 & 0.87 & 0.94 \\ 
		& n=900 & 0.1 & 0.17 & 0.27 & 0.4 & 0.54 & 0.66 & 0.79 & 0.87 & 0.93 \\ 
		\bottomrule
	\end{tabular}
	\label{tbl:et_comp_normal_h1}
\end{table}


% Table for NORMAL_h1
\begin{table}[!h]
	\centering
	\caption{Стандартное нормальное распределение (h1=0)}
	\begin{tabular}{l c c c c c c c c c c} 
		\toprule
		test & sample size & h2=1.0 & h2=1.5 & h2=2.0 & h2=2.5 & h2=3.0 & h2=3.5 & h2=4.0 & h2=4.5 & h2=5.0 \\ 
		\midrule
		\multirow{3}{*}{$\text{ET}_1$} 
		& n=100 & 0.05 & 0.07 & 0.09 & 0.13 & 0.18 & 0.25 & 0.33 & 0.42 & 0.49 \\ 
		& n=400 & 0.06 & 0.09 & 0.13 & 0.2 & 0.27 & 0.38 & 0.51 & 0.62 & 0.74 \\ 
		& n=900 & 0.07 & 0.1 & 0.16 & 0.21 & 0.34 & 0.46 & 0.59 & 0.71 & 0.82 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{$\text{ET}_2$} 
		& n=100 & 0.05 & 0.07 & 0.08 & 0.11 & 0.15 & 0.21 & 0.27 & 0.34 & 0.42 \\ 
		& n=400 & 0.05 & 0.07 & 0.09 & 0.14 & 0.2 & 0.28 & 0.38 & 0.49 & 0.62 \\ 
		& n=900 & 0.06 & 0.08 & 0.11 & 0.16 & 0.23 & 0.33 & 0.45 & 0.57 & 0.7 \\ 
		\bottomrule
	\end{tabular}
	\label{tbl:et_comp_normal_h2}
\end{table}

%aboba
% Table for CAUCHY_h2
\begin{table}[!h]
	\centering
	\caption{Стандартное распределение Коши (h2=0)}
	\begin{tabular}{l c c c c c c c c c c} 
		\toprule
		test & sample size & h1=1.0 & h1=2.0 & h1=3.0 & h1=4.0 & h1=5.0 & h1=6.0 & h1=7.0 & h1=8.0 & h1=9.0 \\ 
		\midrule
		\multirow{3}{*}{$\text{ET}_1$} 
		& n=100 & 0.08 & 0.11 & 0.21 & 0.35 & 0.52 & 0.69 & 0.83 & 0.92 & 0.96 \\ 
		& n=400 & 0.06 & 0.11 & 0.21 & 0.34 & 0.52 & 0.69 & 0.82 & 0.91 & 0.97 \\ 
		& n=900 & 0.07 & 0.12 & 0.22 & 0.36 & 0.53 & 0.71 & 0.83 & 0.92 & 0.97 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{$\text{ET}_2$} 
		& n=100 & 0.06 & 0.07 & 0.07 & 0.07 & 0.08 & 0.09 & 0.11 & 0.14 & 0.19 \\ 
		& n=400 & 0.05 & 0.05 & 0.05 & 0.06 & 0.06 & 0.07 & 0.08 & 0.1 & 0.14 \\ 
		& n=900 & 0.04 & 0.05 & 0.05 & 0.05 & 0.06 & 0.07 & 0.07 & 0.09 & 0.11 \\ 
		\bottomrule
	\end{tabular}
	\label{tbl:et_comp_cauchy_h1}
\end{table}

% Table for CAUCHY_h1
\begin{table}[!h]
	\centering
	\caption{Стандартное распределение Коши (h1=0)}
	\begin{tabular}{l c c c c c c c c c c} 
		\toprule
		test & sample size & h2=1.0 & h2=2.0 & h2=3.0 & h2=4.0 & h2=5.0 & h2=6.0 & h2=7.0 & h2=8.0 & h2=9.0 \\ 
		\midrule
		\multirow{3}{*}{$\text{ET}_1$} 
		& n=100 & 0.05 & 0.09 & 0.12 & 0.18 & 0.26 & 0.34 & 0.42 & 0.48 & 0.58 \\ 
		& n=400 & 0.06 & 0.1 & 0.16 & 0.25 & 0.38 & 0.49 & 0.62 & 0.73 & 0.82 \\ 
		& n=900 & 0.06 & 0.1 & 0.17 & 0.29 & 0.42 & 0.54 & 0.69 & 0.79 & 0.88 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{$\text{ET}_2$} 
		& n=100 & 0.04 & 0.04 & 0.05 & 0.05 & 0.04 & 0.04 & 0.05 & 0.05 & 0.04 \\ 
		& n=400 & 0.05 & 0.05 & 0.05 & 0.05 & 0.05 & 0.05 & 0.05 & 0.06 & 0.07 \\ 
		& n=900 & 0.05 & 0.05 & 0.05 & 0.05 & 0.05 & 0.06 & 0.06 & 0.06 & 0.07 \\ 
		\bottomrule
	\end{tabular}
	\label{tbl:et_comp_cauchy_h2}
\end{table}




\newpage

\section{Анализ результатов}
Как нетрудно заметить, при конфигурациях, соответствующих таблицам~\ref{tbl:ap_normal_h1_diff} и~\ref{tbl:ap_cauchy_h2_diff}, эмпирические мощности довольно быстро сходятся к асимптотическим. Но, например, в таблице~\ref{tbl:ap_cauchy_h1_diff} видно, что сходимость уже не такая быстрая при $h_1 \geq 4$.

В случае стандартных нормальных распределений, отличающихся масштабом, (см. таблицу~\ref{tbl:normal_pow_vs_h2}) самым мощным оказался энергетический тест. Стоит отметить, что ему не сильно уступает тест Андерсона--Дарлинга. А наименее мощным оказался тест Вилкоксона.

В случае стандартных нормальных распределений, отличающихся сдвигом, (см. таблицу~\ref{tbl:normal_pow_vs_h1}) самым мощным оказался тест Вилкоксона. А наименее мощным показал себя тест Колмогорова--Смирнова.

В случае стандартных распределений Коши, отличающихся масштабом, (см. таблицу~\ref{tbl:cauchy_pow_vs_h2}) наиболее мощным оказался энергетический тест. В этот раз тест Андерсона--Дарлинга уже сильно уступает ему. И наименее мощным снова оказался тест Вилкоксона.

В случае стандартных распределений Коши, отличающихся сдвигом,(см. таблицу~\ref{tbl:cauchy_pow_vs_h1}) при $h_1 \leq 5$ наиболее мощным оказался тест Вилкоксона. А при $h_1 > 5$ таковым показал себя тест Колмогорова--Смиронова. При этом отличия между ними довольно незначительны.

Касательно сравнения $\text{ET}_1$ и $\text{ET}_2$ можно сказать следующее:

В случае стандартного нормального распределения $\text{ET}_1$ оказался мощнее. Причём при $h_1=0$ отличие значительное, а при $h_2=0$ не очень.

В случае стандартного распределения Коши $\text{ET}_2$ оказывается мощнее при $h_1 \leqslant 4$ и при $h_2 \leqslant 4$. А при $h_1 \geqslant 5$ и $h_2 \geqslant 5$ наиболее мощным показал себя $\text{ET}_1$.

\bibliographystyle{ugost2008}
\bibliography{refs}


\end{document}