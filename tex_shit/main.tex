\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage{ntheorem}
\usepackage{multirow}
\usepackage{amsmath, amssymb}
\usepackage{indentfirst}

\theoremstyle{break}
\theorembodyfont{\normalfont}
\theoremheaderfont{\bfseries}
\newtheorem{example}{Пример}


\usepackage[
left=1.5cm,    % отступ слева
right=1.5cm,   % отступ справа
top=2cm,     % отступ сверху
bottom=2cm   % отступ снизу
]{geometry}


\title{Потом тут будет титульный лист}
\author{Сивков Вячеслав}
\date{2025}

\begin{document}

\maketitle

\tableofcontents

\section{Введение}
Рассмотрим задачу проверки гипотезы о равенстве двух
распределений

\begin{equation}
	H_0: F_1 = F_2
\end{equation}

\noindent против альтернативы

\begin{equation}
	H_1: F_1 \neq F_2
\end{equation}


\noindent в случае двух независимых выборок $X = (X_1, \ldots,X_n)$ и $Y = (Y_1, \ldots, Y_m)$ с функциями распределения $F_1$ и $F_2$ соответственно.

Один из важных частных случаев этой задачи выглядит следующим образом:
пусть размеры выборок идентичны и равны $n$, пусть $h_1, h_2 \in \mathbb{R}$, $h_1, h_2 \geqslant 0$, пусть $F(x)$ некая функция распределения. Положим
\begin{align}
	&F_1(x) = F(x) \label{eq:F1}\\
	&F_2(x) = F( x(1 + \frac{h_2}{\sqrt{n}}) +  \frac{h_1}{\sqrt{n}}). \label{eq:F2}
\end{align}

Для проверки вышеуказанной гипотезы существует множество тестов. Одними из самых известных являются: тест Вилкоксона--Манна--Уитни, тест Андерсона--Дарлинга, энергетический тест, тест Колмогорова--Смирнова и тест Крамера-фон Мизеса.
В работе~\cite{melas2024} была получена формула для асимптотической мощности энергетического теста при неких ограничениях. 

В данной работе c помощью статистического моделирования была изучена скорость сходимости эмпирических мощностей энергетического теста к асимптотической с ростом размера выборки.
Также было проведено сравнение эмпирических мощностей пяти тестов для различных $F(x), h_1, h_2, n$.





\section{Методы проверки гипотез}

Далее описаны статистики для соответствующих тестов. В каждом из тестов мы отвергаем $H_0$, если значение статистики на выборках $X, Y$ \textbf{больше} чем заранее заданное критическое значение.

\subsection{Энергетический тест}
Пусть $X = (X_1, \ldots,X_n)$ и $Y = (Y_1, \ldots, Y_m)$ независимые выборки. Статистика $\Phi_{nm}$ определяется следующим образом:

\begin{equation}
\begin{aligned}
	\Phi_{nm} = \Phi_{AB} - \Phi_{A} -\Phi_{B}, \quad
	\Phi_{A} = \frac{1}{n^2} \sum_{1 \leq i \leq j \leq n} g(|X_i - X_j|),\\
	\Phi_{B} = \frac{1}{m^2} \sum_{1 \leq i \leq j \leq n} g(|Y_i - Y_j|), \quad
	\Phi_{AB} = \frac{1}{nm} \sum_{i=1}^n \sum_{j=1}^m g(|X_i - Y_j|),
\end{aligned}
\end{equation}
где $g(x)$ - непрерывная, монотонно возрастающая функция.\\
\noindent Для рассматриваемой в этой работе задачи $n = m$. 
\subsection{Тест Андерсона--Дарлинга для нескольких выборок}

Пусть $k \in \mathbb{N}$ -- количество выборок. Пусть $n_i$ -- размер $i$-й выборки, $ i \in \overline{1, \ldots, k} $. Пусть $N = n_1 + \ldots + n_k$. Обозначим за $M_{ij}$ количество 
элементов $i$-й выборки, которые не больше чем $Z_{(j)}$, где $(Z_{(1)}, \ldots, Z_{(N)})$ - вариационный ряд, построенный по всем имеющимся $k$ выборкам. Тогда статистика будет выглядеть следующим образом:

\begin{equation}
	A_{kN}^2 = \frac{1}{N} \sum_{i=1}^k \frac{1}{n_i} \sum_{j=1}^{N-1} \frac{(NM_{ij}-jn_i)^2}{j(N-j)}.
\end{equation}

\noindent Для рассматриваемой в этой работе задачи $k=2$, $n_1 = n_2 = n$. 

\subsection{Тест Колмогорова--Смирнова}
Пусть $X = (X_1, \ldots,X_n)$ и $Y = (Y_1, \ldots, Y_m)$ независимые выборки. Пусть $N = n + m$.
Пусть $(Z_{(1)}, \ldots, Z_{(N)})$ - вариационный ряд, построенный по выборкам $X$ и $Y$. Обозначим за $\hat{F}$ и $\hat{G}$ эмпирические функции распределения построенные по выборкам $X$ и $Y$. Тогда статистика будет выглядеть так:
\begin{equation}
	KS = \max_{1\leq i \leq N} | \hat{F}(Z_{(i)}) - \hat{G}(Z_{(i)})  |
\end{equation}

\noindent Для рассматриваемой в этой работе задачи $n = m$. 

\subsection{Тест Крамера-фон Мизеса}
Пусть $X = (X_1, \ldots,X_n)$ и $Y = (Y_1, \ldots, Y_m)$ независимые выборки. Пусть $N = n + m$.
Пусть $(Z_{(1)}, \ldots, Z_{(N)})$ - вариационный ряд, построенный по выборкам $X$ и $Y$. Обозначим за $\hat{F}$ и $\hat{G}$ эмпирические функции распределения построенные по выборкам $X$ и $Y$. Тогда статистика будет выглядеть следующим образом:
\begin{equation}
	CM = \frac{mn}{N^2} \sum_{i=1}^{N} (\hat{F}(Z_{(i)}) - \hat{G}(Z_{(i)}))^2
\end{equation}

\noindent Для рассматриваемой в этой работе задачи $n = m$. 

\subsection{Тест Вилкоксона--Манна--Уитни}
Пусть $X = (X_1, \ldots,X_n)$ и $Y = (Y_1, \ldots, Y_m)$ независимые выборки. Статистика будет выглядеть следующим образом:
\begin{equation}
	U_{nm} = \sum_{i=1}^n \sum_{j=1}^m \chi(X_i,Y_j),
\end{equation}
где
\begin{equation}
	\chi(X_i,Y_j) = 
	\begin{cases}
		1, \ X_i \geq Y_j \\
		0, \ X_i < Y_j
	\end{cases}
\end{equation}


\noindent Для рассматриваемой в этой работе задачи $n = m$. 

\section{Описание эксперимента}
О том, как проводилось вычисление эмпирических мощностей.

Выбираем некий тест $T(X,Y)$. Фиксируем некую функцию распределения $F(x)$. Фиксируем $n \in \mathbb{N}$ -- размер выборок. Фиксируем $h_1, h_2 \in \mathbb{R}$, $h_1, h_2 \geqslant 0$ -- параметры отличия по сдвигу и масштабу соответственно. $F_1$ и $F_2$ определяем как было указано в~\eqref{eq:F1} и~\eqref{eq:F2} соответственно. Фиксируем $\alpha \in (0,1)$ -- уровень значимости. Выбираем $N \in \mathbb{N}$ и $M \in \mathbb{N}$.

Сначала приближённо вычисляем критическое значение $c_{\alpha}$ для выбранного ранее теста так, чтобы он имел уровень значимости $\alpha$ следующим образом:

\begin{enumerate}
	\item 
	\item Получаем выборку из распределения $T(X,Y)$ размера $???$, по ней строим эмпирическое распределение $\hat{T}(X,Y)$.
	\item В качестве $c_{\alpha}$ берём $1 - \alpha$ квантиль $\hat{T}(X,Y)$.
\end{enumerate}

\newpage
\section{Результаты}
Всюду далее $g(x) = \ln(1+x^2)$.

\begin{example}
Пусть $F_1(x) = F(x)$ и $F_{2,n}(x) = F(x(1 + \frac{h_2}{\sqrt{n}})+ \frac{h_1}{\sqrt{n}} )$, где $F(x)$ - ф-я стандартного нормального распределения.\\
Пусть $\alpha = 0.05$.
С помощью численного интегрирования были получены значения:
\begin{equation*}
	J_1 = 0.810113 \hspace{0.1in} J_2 = 1.154885 \hspace{0.1in}  J_3=0.763368 \hspace{0.1in}
	\frac{J^{*}_1(h_1)}{{h_1}^2} = 0.227179   \hspace{0.1in} \frac{J^{*}_2(h_2)}{{h_2}^2} = 0.147563
\end{equation*}
В таблицах \ref{tbl:ap_normal_h2_diff} и \ref{tbl:ap_normal_h1_diff} представлены значения асимптотической мощности, вычисленные по формуле,
и эмпирические мощности, полученные в результате $N = 5000$ повторений статистического
моделирования двух выборок размера $n = 100$, $400$, $900$, $1600$, $2000$, $3000$. Критическое значение
критерия $nT_n$ вычислялось с помощью $M=5000$ случайных перестановок, как $1-\alpha$ квантиль эмпирического распределения $nT_n$, построенного по выборке размера $M$. Для вычисления значений в таблице 1 было взято значение $h_1=0$, для вычисления значений в таблице 2 было взято значение $h_2=0$.
\end{example}


%normal h1
\begin{table}[!h]
	\caption{Значения эмпирической (EP) и асимптотической (AP) мощности ($h_1=0$)}
	\centering
	\hspace*{-1.0cm}\begin{tabular}
		{lrrrrrrrrrr}
		\toprule
		& h2=0.5 & h2=1.0 & h2=1.5 & h2=2.0 & h2=2.5 & h2=3.0 & h2=3.5 & h2=4.0 & h2=4.5 & h2=5.0\\
		\midrule
		EP (n=100) & 0.055 & 0.060 & 0.085 & 0.105 & 0.155 & 0.215 & 0.275 & 0.359 & 0.445 & 0.545\\
		EP (n=400) & 0.057 & 0.069 & 0.096 & 0.138 & 0.209 & 0.299 & 0.415 & 0.534 & 0.657 & 0.757\\
		EP (n=900) & 0.049 & 0.067 & 0.095 & 0.143 & 0.212 & 0.316 & 0.442 & 0.579 & 0.706 & 0.810\\
		EP (n=1600) & 0.045 & 0.059 & 0.074 & 0.126 & 0.181 & 0.297 & 0.408 & 0.554 & 0.689 & 0.796\\
		EP (n=2000) & 0.051 & 0.066 & 0.103 & 0.143 & 0.220 & 0.325 & 0.467 & 0.603 & 0.741 & 0.837\\
		EP (n=3000) & 0.056 & 0.067 & 0.102 & 0.157 & 0.235 & 0.337 & 0.489 & 0.637 & 0.760 & 0.868\\
		\addlinespace
		AP & 0.058 & 0.082 & 0.124 & 0.183 & 0.260 & 0.351 & 0.453 & 0.557 & 0.658 & 0.749\\
		\bottomrule
	\end{tabular}
	\label{tbl:ap_normal_h2_diff}
\end{table}






%normal h2
\begin{table}[!h]
	\centering
	\caption{Значения эмпирической (EP) и асимптотической (AP) мощности ($h_2=0$)}
	\hspace*{-1.0cm}\begin{tabular}
		{lrrrrrrrrrr}
		\toprule
		& h1=1.0 & h1=2.0 & h1=3.0 & h1=4.0 & h1=5.0 & h1=6.0 & h1=7.0 & h1=8.0 & h1=9.0 & h1=10.0\\
		\midrule
		EP (n=100) & 0.083 & 0.236 & 0.476 & 0.729 & 0.904 & 0.974 & 0.997 & 1.000 & 1 & 1\\
		EP (n=400) & 0.115 & 0.275 & 0.558 & 0.783 & 0.932 & 0.985 & 1.000 & 0.999 & 1 & 1\\
		EP (n=900) & 0.106 & 0.291 & 0.531 & 0.782 & 0.922 & 0.985 & 0.997 & 1.000 & 1 & 1\\
		EP (n=1600) & 0.102 & 0.271 & 0.524 & 0.759 & 0.914 & 0.982 & 0.996 & 1.000 & 1 & 1\\
		EP (n=2000) & 0.116 & 0.278 & 0.531 & 0.781 & 0.926 & 0.985 & 0.998 & 1.000 & 1 & 1\\
		EP (n=3000) & 0.102 & 0.270 & 0.541 & 0.762 & 0.915 & 0.983 & 0.997 & 1.000 & 1 & 1\\
		\addlinespace
		AP & 0.100 & 0.257 & 0.499 & 0.742 & 0.904 & 0.975 & 0.995 & 0.999 & 1 & 1\\
		\bottomrule
	\end{tabular}
	\label{tbl:ap_normal_h1_diff}
\end{table}


\newpage


\begin{example}
	Пусть $F_1(x) = F(x)$ и $F_{2,n}(x) = F(x(1 + \frac{h_2}{\sqrt{n}})+ \frac{h_1}{\sqrt{n}} )$, где $F(x)$ - ф-я стандартного распределения Коши.\\
	Пусть $h_1=0$, $\alpha = 0.05$.
	С помощью численного интегрирования были получены значения:
	\begin{equation*}
		J_1 = 2.197224 \hspace{0.1in} J_2 = 9.577512 \hspace{0.1in}  J_3=6.881056 \hspace{0.1in}
		\frac{J^{*}_1(h_1)}{{h_1}^2} = 0.111110   \hspace{0.1in} \frac{J^{*}_2(h_2)}{{h_2}^2} = 0.111105
	\end{equation*}
	В таблицах \ref{tbl:ap_cauchy_h2_diff} и \ref{tbl:ap_cauchy_h1_diff} представлены значения асимптотической мощности, вычисленные по формуле,
	и эмпирические мощности, полученные в результате $N = 5000$ повторений статистического
	моделирования двух выборок размера $n = 100$, $400$, $900$, $1600$, $2000$, $3000$. Критическое значение
	критерия $nT_n$ вычислялось с помощью $M=5000$ случайных перестановок, как $1-\alpha$ квантиль эмпирического распределения $nT_n$, построенного по выборке размера $M$. Для вычисления значений в таблице 3 было взято значение $h_1=0$, для вычисления значений в таблице 4 было взято значение $h_2=0$.
\end{example}

%cauchy h1
\begin{table}[!h]
	\caption{Значения эмпирической (EP) и асимптотической (AP) мощности ($h_1=0$)}
	\centering
	\hspace*{-1.0cm}\begin{tabular}
		{lrrrrrrrrrr}
		\toprule
		& h2=1.0 & h2=2.0 & h2=3.0 & h2=4.0 & h2=5.0 & h2=6.0 & h2=7.0 & h2=8.0 & h2=9.0 & h2=10.0\\
		\midrule
		EP (n=100) & 0.058 & 0.080 & 0.127 & 0.189 & 0.256 & 0.327 & 0.412 & 0.498 & 0.574 & 0.645\\
		EP (n=400) & 0.048 & 0.083 & 0.137 & 0.218 & 0.332 & 0.452 & 0.568 & 0.675 & 0.773 & 0.843\\
		EP (n=900) & 0.056 & 0.097 & 0.165 & 0.265 & 0.403 & 0.536 & 0.665 & 0.783 & 0.865 & 0.924\\
		EP (n=1600) & 0.066 & 0.107 & 0.179 & 0.285 & 0.442 & 0.585 & 0.716 & 0.818 & 0.907 & 0.949\\
		EP (n=2000) & 0.056 & 0.109 & 0.170 & 0.298 & 0.432 & 0.571 & 0.719 & 0.837 & 0.907 & 0.951\\
		EP (n=3000) & 0.057 & 0.108 & 0.168 & 0.297 & 0.445 & 0.597 & 0.736 & 0.856 & 0.924 & 0.965\\
		\addlinespace
		AP & 0.066 & 0.115 & 0.201 & 0.319 & 0.461 & 0.608 & 0.741 & 0.846 & 0.918 & 0.961\\
		\bottomrule
	\end{tabular}
	\label{tbl:ap_cauchy_h2_diff}
\end{table}

%caychy h2 new
\begin{table}[!h]
	\centering
	\caption{Значения эмпирической (EP) и асимптотической (AP) мощности ($h_2=2$)}
	\centering
	\hspace*{-1.0cm}\begin{tabular}
		[t]{lrrrrrrrrrr}
		\toprule
		& h1=1.0 & h1=2.0 & h1=3.0 & h1=4.0 & h1=5.0 & h1=6.0 & h1=7.0 & h1=8.0 & h1=9.0 & h1=10.0\\
		\midrule
		EP (n=100) & 0.096 & 0.137 & 0.200 & 0.318 & 0.446 & 0.583 & 0.735 & 0.833 & 0.917 & 0.962\\
		EP (n=400) & 0.107 & 0.155 & 0.238 & 0.359 & 0.504 & 0.662 & 0.788 & 0.887 & 0.951 & 0.982\\
		EP (n=900) & 0.116 & 0.168 & 0.257 & 0.384 & 0.523 & 0.683 & 0.807 & 0.904 & 0.958 & 0.985\\
		EP (n=1600) & 0.114 & 0.171 & 0.250 & 0.380 & 0.537 & 0.688 & 0.823 & 0.905 & 0.965 & 0.986\\
		EP (n=2000) & 0.138 & 0.178 & 0.295 & 0.407 & 0.552 & 0.714 & 0.846 & 0.921 & 0.962 & 0.989\\
		
		EP (n=3000) & 0.131 & 0.181 & 0.269 & 0.394 & 0.566 & 0.708 & 0.837 & 0.932 & 0.967 & 0.991\\
		\addlinespace
		AP & 0.132 & 0.183 & 0.269 & 0.384 & 0.518 & 0.653 & 0.773 & 0.866 & 0.929 & 0.967\\
		\bottomrule
	\end{tabular}
	\label{tbl:ap_cauchy_h1_diff}
\end{table}


\newpage

В таблицах \ref{tbl:normal_pow_vs_h2} - \ref{tbl:cauchy_pow_vs_h1} представлены эмпирические мощности 5 тестов.\\

% Table for NORMAL_h1
\begin{table}[!h]
	\centering
	\caption{Стандартное нормальное распределение (h1=0) }
	\begin{tabular}{l c c c c c c} 
		\toprule
		test & sample size & h2=1.0 & h2=2.0 & h2=3.0 & h2=4.0 & h2=5.0 \\ 
		\midrule
		\multirow{3}{*}{AD} 
		& n=100 & 0.06 & 0.11 & 0.22 & 0.38 & 0.58 \\ 
		& n=400 & 0.06 & 0.12 & 0.25 & 0.49 & 0.73 \\ 
		& n=900 & \textbf{0.07} & \textbf{0.14} & 0.3 & \textbf{0.58} & \textbf{0.81} \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{CM} 
		& n=100 & 0.05 & 0.07 & 0.12 & 0.19 & 0.32 \\ 
		& n=400 & 0.05 & 0.07 & 0.14 & 0.26 & 0.44 \\ 
		& n=900 & 0.06 & 0.09 & 0.14 & 0.28 & 0.47 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{ET} 
		& n=100 & 0.06 & 0.1 & 0.19 & 0.35 & 0.51 \\ 
		& n=400 & \textbf{0.07} & 0.13 & 0.28 & 0.51 & 0.75 \\ 
		& n=900 & \textbf{0.07} & \textbf{0.14} & \textbf{0.33} & \textbf{0.58} & \textbf{0.81} \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{KS} 
		& n=100 & 0.06 & 0.08 & 0.12 & 0.2 & 0.3 \\ 
		& n=400 & 0.06 & 0.09 & 0.14 & 0.24 & 0.39 \\ 
		& n=900 & 0.06 & 0.1 & 0.17 & 0.28 & 0.43 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{WMW} 
		& n=100 & 0.05 & 0.05 & 0.06 & 0.05 & 0.05 \\ 
		& n=400 & 0.05 & 0.05 & 0.06 & 0.06 & 0.06 \\ 
		& n=900 & 0.05 & 0.05 & 0.05 & 0.05 & 0.05 \\ 
		\bottomrule
	\end{tabular}
	\label{tbl:normal_pow_vs_h2}
\end{table}

% Table for NORMAL_h2
\begin{table}[!h]
	\centering
	\caption{Стандартное нормальное распределение (h2=0)}
	\begin{tabular}{l c c c c c c} 
		\toprule
		test & sample size & h1=1.0 & h1=3.0 & h1=5.0 & h1=7.0 & h1=9.0 \\ 
		\midrule
		\multirow{3}{*}{AD} 
		& n=100 & 0.09 & 0.51 & 0.92 & 1 & 1 \\ 
		& n=400 & 0.11 & 0.55 & 0.93 & 1 & 1 \\ 
		& n=900 & 0.11 & 0.54 & 0.93 & 1 & 1 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{CM} 
		& n=100 & 0.11 & 0.54 & 0.92 & 1 & 1 \\ 
		& n=400 & 0.11 & 0.53 & 0.92 & 1 & 1 \\ 
		& n=900 & 0.1 & 0.52 & 0.92 & 1 & 1 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{ET} 
		& n=100 & 0.1 & 0.53 & 0.92 & 1 & 1 \\ 
		& n=400 & 0.1 & 0.54 & 0.92 & 1 & 1 \\ 
		& n=900 & 0.09 & 0.5 & 0.91 & 1 & 1 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{KS} 
		& n=100 & 0.12 & 0.49 & 0.89 & 0.99 & 1 \\ 
		& n=400 & 0.1 & 0.43 & 0.88 & 0.99 & 1 \\ 
		& n=900 & 0.1 & 0.46 & 0.87 & 0.99 & 1 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{WMW} 
		& n=100 & \textbf{0.18} & 0.66 & \textbf{0.97} & 1 & 1 \\ 
		& n=400 & 0.17 & \textbf{0.67} & \textbf{0.97} & 1 & 1 \\ 
		& n=900 & \textbf{0.18} & \textbf{0.67} & 0.96 & 1 & 1 \\ 
		\bottomrule
	\end{tabular}
	\label{tbl:normal_pow_vs_h1}
\end{table}

\newpage

% Table for CAUCHY_h1
\begin{table}[!h]
	\centering
	\caption{Стандартное распределение Коши (h1=0)}
	\begin{tabular}{l c c c c c c} 
		\toprule
		test & sample size & h2=1.0 & h2=3.0 & h2=5.0 & h2=7.0 & h2=9.0 \\ 
		\midrule
		\multirow{3}{*}{AD} 
		& n=100 & 0.05 & 0.07 & 0.14 & 0.26 & 0.41 \\ 
		& n=400 & 0.05 & 0.09 & 0.21 & 0.4 & 0.64 \\ 
		& n=900 & 0.05 & 0.1 & 0.22 & 0.46 & 0.71 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{CM} 
		& n=100 & 0.06 & 0.08 & 0.13 & 0.22 & 0.36 \\ 
		& n=400 & 0.05 & 0.08 & 0.17 & 0.33 & 0.53 \\ 
		& n=900 & 0.05 & 0.08 & 0.17 & 0.36 & 0.61 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{ET} 
		& n=100 & \textbf{0.09} & \textbf{0.18} & 0.35 & 0.52 & 0.69 \\ 
		& n=400 & 0.06 & 0.15 & 0.34 & 0.58 & 0.79 \\ 
		& n=900 & 0.06 & \textbf{0.18} & \textbf{0.42} & \textbf{0.69} & \textbf{0.88} \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{KS} 
		& n=100 & 0.05 & 0.09 & 0.16 & 0.25 & 0.38 \\ 
		& n=400 & 0.06 & 0.11 & 0.2 & 0.35 & 0.56 \\ 
		& n=900 & 0.06 & 0.12 & 0.23 & 0.39 & 0.61 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{WMW} 
		& n=100 & 0.05 & 0.05 & 0.05 & 0.05 & 0.05 \\ 
		& n=400 & 0.05 & 0.05 & 0.05 & 0.05 & 0.05 \\ 
		& n=900 & 0.05 & 0.04 & 0.05 & 0.04 & 0.04 \\ 
		\bottomrule
	\end{tabular}
	\label{tbl:cauchy_pow_vs_h2}
\end{table}



% Table for CAUCHY_h2
\begin{table}[!h]
	\centering
	\caption{Стандартное распределение Коши (h2=0)}
	\begin{tabular}{l c c c c c c} 
		\toprule
		test & sample size & h1=1.0 & h1=3.0 & h1=5.0 & h1=7.0 & h1=9.0 \\ 
		\midrule
		\multirow{3}{*}{AD} 
		& n=100 & 0.06 & 0.21 & 0.51 & 0.79 & 0.94 \\ 
		& n=400 & 0.07 & 0.22 & 0.53 & 0.82 & 0.96 \\ 
		& n=900 & 0.07 & 0.21 & 0.53 & 0.81 & 0.96 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{CM} 
		& n=100 & 0.07 & 0.24 & 0.54 & 0.83 & 0.96 \\ 
		& n=400 & 0.07 & 0.26 & 0.58 & 0.86 & 0.97 \\ 
		& n=900 & 0.06 & 0.23 & 0.57 & 0.86 & 0.97 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{ET} 
		& n=100 & 0.07 & 0.2 & 0.52 & 0.83 & 0.96 \\ 
		& n=400 & 0.08 & 0.23 & 0.56 & 0.84 & 0.97 \\ 
		& n=900 & 0.07 & 0.2 & 0.51 & 0.82 & 0.97 \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{KS} 
		& n=100 & 0.07 & 0.26 & 0.56 & 0.85 & 0.97 \\ 
		& n=400 & 0.08 & 0.26 & 0.6 & \textbf{0.87} & \textbf{0.98} \\ 
		& n=900 & 0.08 & 0.27 & 0.59 & \textbf{0.87} & \textbf{0.98} \\ 
		\addlinespace
		\addlinespace
		\multirow{3}{*}{WMW} 
		& n=100 & 0.1 & 0.3 & 0.57 & 0.83 & 0.94 \\ 
		& n=400 & 0.09 & 0.3 & \textbf{0.61} & 0.84 & 0.96 \\ 
		& n=900 & \textbf{0.11} & \textbf{0.32} & \textbf{0.61} & 0.85 & 0.97 \\ 
		\bottomrule
	\end{tabular}
	\label{tbl:cauchy_pow_vs_h1}
\end{table}



\vspace{0.1in}
Далее, на рис. \ref{fig:normal_pow_vs_h2} - рис. \ref{fig:cauchy_pow_vs_h1} представлены зависимости эмпирических мощностей от различий по масштабу/сдвигу, и на рис. \ref{fig:normal_pow_vs_n_h2_diff} - рис. \ref{fig:cauchy_pow_vs_n_h1_diff} представлены зависимости эмпирических мощностей от размера выборки.\\


\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics/NORMAL_h1_n_EP (n_500).png}
	\caption{Зависимость эмпирических мощностей от различия по масштабу, в случае стандартных нормальных распределений с одинаковым сдвигом.}
	\label{fig:normal_pow_vs_h2}
\end{figure}


\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics/NORMAL_h2_n_EP (n_500).png}
	\caption{Зависимость эмпирических мощностей от различия по сдвигу, в случае стандартных нормальных распределений с одинаковым масштабом.}
	\label{fig:normal_pow_vs_h1}
\end{figure}



\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics/CAUCHY_h1_n_EP (n_500).png}
	\caption{Зависимость эмпирических мощностей от различия по масштабу, в случае стандартных распределений Коши с одинаковым сдвигом.}
	\label{fig:cauchy_pow_vs_h2}
\end{figure}



\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics/CAUCHY_h2_n_EP (n_500).png}
	\caption{Зависимость эмпирических мощностей от различия по сдвигу, в случае стандартных распределений Коши с одинаковым масштабом.}
	\label{fig:cauchy_pow_vs_h1}
\end{figure}



\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics2/NORMAL_h1_h2_2.5.png}
	\caption{Зависимость эмпирических мощностей от размера выборки в случае стандартных нормальных распределений, отличающихся масштабом.}
	\label{fig:normal_pow_vs_n_h2_diff}
\end{figure}



\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics2/NORMAL_h2_h1_5.0.png}
	\caption{Зависимость эмпирических мощностей от размера выборки в случае стандартных нормальных распределений, отличающихся сдвигом.}
	\label{fig:normal_pow_vs_n_h1_diff}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics2/CAUCHY_h1_h2_7.0.png}
	\caption{Зависимость эмпирических мощностей от размера выборки в случае стандартных распределений Коши, отличающихся масштабом.}
	\label{fig:cauchy_pow_vs_n_h2_diff}
\end{figure}



\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{pics2/CAUCHY_h2_h1_6.0.png}
	\caption{Зависимость эмпирических мощностей от размера выборки в случае стандартных распределений Коши, отличающихся сдвигом.}
	\label{fig:cauchy_pow_vs_n_h1_diff}
\end{figure}



\clearpage
\section{Анализ результатов}
text

\bibliographystyle{ugost2008}
\bibliography{refs}


\end{document}